"""
swarm_orchestrator.py - Orchestrateur du syst√®me multi-agents
G√®re le flux d'ex√©cution et la boucle de self-healing
VERSION FIX√âE - Le Juge g√©n√®re ET ex√©cute les tests
VERSION MODIFI√âE - Succ√®s si au moins 80% des tests passent
"""
import sys
from pathlib import Path
from typing import Dict, List


from src.agents.auditor_agent import AuditorAgent
from src.agents.fixer_agent import FixerAgent
from src.agents.judge_agent import JudgeAgent
from src.tools.file_manager import list_python_files, backup_file
from src.utils.logger import log_experiment, ActionType


class RefactoringSwarm:
    """
    Orchestrateur principal du syst√®me de refactoring
    G√®re la collaboration entre les agents selon le sch√©ma:
    Auditeur ‚Üí Correcteur ‚Üí Juge (g√©n√®re tests + valide) ‚Üí (loop si √©chec)
    """
    
    # ========================================
    # CONFIGURATION CONSTANTS
    # ========================================
    
    # Success threshold: minimum percentage of tests that must pass
    SUCCESS_THRESHOLD = 0.80  # 80% of tests must pass for success
    
    def __init__(self, target_directory: Path, max_iterations: int = 3, success_threshold: float = None):
        """
        Initialise l'orchestrateur
        
        Args:
            target_directory: Dossier contenant le code √† refactorer
            max_iterations: Nombre maximum d'it√©rations de self-healing
            success_threshold: Seuil de r√©ussite (0.0 √† 1.0). Si None, utilise SUCCESS_THRESHOLD
        """
        self.target_directory = Path(target_directory)
        self.max_iterations = max_iterations
        self.current_iteration = 0
        
        # Configurer le seuil de succ√®s
        if success_threshold is not None:
            if not 0.0 <= success_threshold <= 1.0:
                raise ValueError(f"success_threshold doit √™tre entre 0.0 et 1.0, re√ßu: {success_threshold}")
            self.success_threshold = success_threshold
        else:
            self.success_threshold = self.SUCCESS_THRESHOLD
        
        # Initialiser les agents
        print("üîß Initialisation des agents...")
        self.auditor = AuditorAgent()
        self.fixer = FixerAgent()
        self.judge = JudgeAgent()  # Juge = G√©n√®re tests + Ex√©cute tests
        
        print(f"‚úÖ Agents pr√™ts : Auditeur, Correcteur, Juge")
        print(f"üìä Seuil de succ√®s configur√© : {self.success_threshold * 100:.0f}% des tests doivent passer\n")
    
    def _discover_files(self) -> List[str]:
        """D√©couvre les fichiers Python √† traiter"""
        files = list_python_files(str(self.target_directory))
        print(f"üì¶ {len(files)} fichiers Python d√©tect√©s\n")
        return files
    
    def _cleanup_test_directory(self):
        """Nettoie le r√©pertoire de tests dans sandbox avant de commencer"""
        test_dir = self.target_directory / "tests"
        
        if test_dir.exists():
            import shutil
            try:
                print(f"üßπ Nettoyage du r√©pertoire {test_dir}...")
                shutil.rmtree(test_dir)
                print(f"   ‚úÖ R√©pertoire {test_dir} supprim√©")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Impossible de supprimer {test_dir}: {e}")
        else:
            print(f"‚ÑπÔ∏è  Aucun r√©pertoire de tests √† nettoyer dans {self.target_directory}")
        
        print()
    
    def _phase_audit(self, files: List[str]) -> Dict:
        """
        Phase 1: Audit du code
        L'Auditeur analyse le code et produit un plan
        """
        print("\nüîç Phase 1/4 : Audit du code...\n")
        print("   üìã Analyse statique du code...")
        print("   üîé Recherche de bugs et violations PEP8...")
        
        plan = self.auditor.analyze(files)
        
        total_issues = sum(len(f.get("issues", [])) for f in plan.get("issues", []))
        print(f"\n   ‚úÖ Plan de refactoring g√©n√©r√© ({total_issues} probl√®mes d√©tect√©s)")
        
        return plan
    
    def _phase_test_generation(self, files: List[str]) -> Dict:
        """
        Phase 2: G√©n√©ration des tests intelligents
        Le Juge cr√©e des tests bas√©s sur l'INTENTION des fonctions
        """
        print("\nüß™ Phase 2/4 : G√©n√©ration des tests intelligents...\n")
        print("   üß† Analyse du code pour comprendre la logique m√©tier...")
        print("   üìù G√©n√©ration de tests par le Juge...")
        
        test_files = []
        for file_path in files:
            # Le JUGE g√©n√®re les tests (pas un agent s√©par√©)
            test_file = self.judge.generate_tests(file_path, self.target_directory)
            if test_file:
                test_files.append(test_file)
        
        if test_files:
            print(f"      ‚úÖ Tests g√©n√©r√©s: {', '.join([Path(f).name for f in test_files])}")
        
        print(f"   ‚úÖ {len(test_files)} fichiers de tests cr√©√©s")
        
        return {
            "test_files": test_files,
            "status": "completed"
        }
    
    def _phase_fix(self, plan: Dict, error_logs: List = None) -> Dict:
        """
        Phase 3: Application des corrections
        Le Fixer modifie le code selon le plan
        """
        print("\nüîß Phase 3/4 : Application des corrections...\n")
        print("   üõ†Ô∏è  Lecture du plan de refactoring...")
        print("   ‚úèÔ∏è  Modification du code fichier par fichier...")
        
        result = self.fixer.fix(plan, error_logs)
        
        print(f"\n   ‚úÖ {len(result['files_modified'])} fichiers modifi√©s")
        print(f"   üêõ {result['bugs_fixed']} corrections appliqu√©es")
        
        return result
    
    def _phase_validation(self, files: List[str]) -> Dict:
        """
        Phase 4: Validation par le Juge
        Le Juge ex√©cute les tests qu'il a g√©n√©r√©s
        """
        print("\n‚öñÔ∏è  Phase 4/4 : Validation par le Juge...\n")
        
        # Le JUGE fait tout: syntaxe + ex√©cution des tests
        validation_result = self.judge.validate(files, self.target_directory)
        
        return validation_result
    
    def _evaluate_success(self, validation_result: Dict) -> tuple[bool, str]:
        """
        √âvalue si le refactoring est r√©ussi selon le seuil configur√©
        
        Args:
            validation_result: R√©sultats de validation du Juge
            
        Returns:
            Tuple (success: bool, reason: str)
        """
        # Si le Juge a d√©tect√© des erreurs de syntaxe, √©chec automatique
        gate_failed = validation_result.get("gate_failed", None)
        if gate_failed == "syntax":
            return False, "Erreurs de syntaxe d√©tect√©es"
        
        # Calculer le pourcentage de tests r√©ussis
        tests_passed = validation_result.get("tests_passed", 0)
        tests_total = validation_result.get("tests_total", 0)
        
        # Cas o√π aucun test n'existe (traiter comme un avertissement, pas un √©chec)
        if tests_total == 0:
            print("   ‚ö†Ô∏è  AVERTISSEMENT: Aucun test disponible pour valider le code")
            return True, "Aucun test disponible (validation impossible)"
        
        # Calculer le taux de r√©ussite
        success_rate = tests_passed / tests_total
        
        print(f"\n   üìä Taux de r√©ussite: {success_rate * 100:.1f}% ({tests_passed}/{tests_total} tests)")
        print(f"   üéØ Seuil requis: {self.success_threshold * 100:.0f}%")
        
        # V√©rifier si on atteint le seuil
        if success_rate >= self.success_threshold:
            return True, f"{success_rate * 100:.1f}% des tests passent (>= {self.success_threshold * 100:.0f}% requis)"
        else:
            tests_needed = int(self.success_threshold * tests_total) - tests_passed
            return False, f"Seulement {success_rate * 100:.1f}% des tests passent, {tests_needed} test(s) de plus n√©cessaire(s)"
    
    def _self_healing_iteration(self, plan: Dict, validation_result: Dict) -> Dict:
        """
        Boucle de self-healing
        Le Fixer r√©essaie en tenant compte des erreurs
        """
        print("\n" + "-" * 70)
        print("       üîÑ Pr√©paration de l'it√©ration suivante (Self-Healing)...")
        
        gate_failed = validation_result.get("gate_failed", "unknown")
        
        if gate_failed == "syntax":
            print("             Correction des erreurs de syntaxe...")
        elif gate_failed == "tests":
            failed_count = validation_result.get("tests_failed", 0)
            print(f"             Correction de {failed_count} erreur(s) de logique m√©tier...")
        else:
            # Cas o√π on a un pourcentage insuffisant mais pas d'√©chec cat√©gorique
            tests_passed = validation_result.get("tests_passed", 0)
            tests_total = validation_result.get("tests_total", 1)
            success_rate = tests_passed / tests_total if tests_total > 0 else 0
            print(f"             Am√©lioration du taux de r√©ussite ({success_rate * 100:.1f}% ‚Üí {self.success_threshold * 100:.0f}% cible)...")
        
        print("-" * 70)
        
        # R√©cup√©rer les erreurs pour informer le Fixer
        error_logs = validation_result.get("errors", [])
        
        # R√©appliquer les corrections avec le contexte d'erreur
        fix_result = self._phase_fix(plan, error_logs)
        
        return fix_result
    
    def run(self) -> Dict:
        """
        Ex√©cute le processus complet de refactoring
        
        Returns:
            Dict avec les r√©sultats finaux
        """
        # Nettoyer le r√©pertoire de tests dans sandbox
        self._cleanup_test_directory()
        
        # D√©couverte des fichiers
        files = self._discover_files()
        
        if not files:
            return {
                "success": False,
                "error": "Aucun fichier Python trouv√©",
                "iterations_used": 0,
                "files_processed": 0,
                "bugs_fixed": 0,
                "tests_passed": 0,
                "total_tests": 0,
                "success_rate": 0.0,
                "threshold": self.success_threshold
            }
        
        # Sauvegarder les fichiers originaux
        print("üíæ Sauvegarde des fichiers originaux...")
        for file_path in files:
            try:
                backup_file(file_path)
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Impossible de sauvegarder {file_path}: {e}")
        
        # Phase 1: Audit initial
        plan = self._phase_audit(files)
        
        # Phase 2: G√©n√©ration des tests (par le Juge)
        test_gen_result = self._phase_test_generation(files)
        
        total_bugs_fixed = 0
        last_validation = None
        
        # Boucle de refactoring avec self-healing
        for iteration in range(1, self.max_iterations + 1):
            self.current_iteration = iteration
            
            print("\n" + "=" * 70)
            print(f"                           üîÑ IT√âRATION {iteration}/{self.max_iterations}")
            print("=" * 70)
            
            # Phase 3: Correction
            if iteration == 1:
                fix_result = self._phase_fix(plan)
            else:
                # Self-healing avec les erreurs de l'it√©ration pr√©c√©dente
                fix_result = self._self_healing_iteration(plan, last_validation)
            
            total_bugs_fixed += fix_result.get("bugs_fixed", 0)
            
            # Phase 4: Validation (par le Juge)
            validation_result = self._phase_validation(files)
            last_validation = validation_result
            
           
            # Calculer les m√©triques finales
            tests_passed = validation_result.get("tests_passed", 0)
            tests_total = validation_result.get("tests_total", 0)
            success_rate = (tests_passed / tests_total) if tests_total > 0 else 0.0
            
                # Succ√®s imm√©diat si TOUS les tests passent
            if tests_total > 0 and tests_passed == tests_total:
                print("\n" + "=" * 70)
                print("                ‚úÖ SUCC√àS - Tous les tests r√©ussis!")
                print("=" * 70)

                return {
                "success": True,
                "reason": "Tous les tests ont √©t√© valid√©s avant la limite d'it√©rations",
                "iterations_used": iteration,
                "files_processed": len(files),
                "bugs_fixed": total_bugs_fixed,
                "tests_passed": tests_passed,
                "total_tests": tests_total,
                "success_rate": success_rate,
                "threshold": self.success_threshold,
                "output_directory": str(self.target_directory)
               }

            
            # Si c'est la derni√®re it√©ration et on a encore √©chou√©
            if iteration == self.max_iterations:
                # NOUVELLE LOGIQUE: √âvaluer le succ√®s selon le seuil
              is_successful, reason = self._evaluate_success(validation_result)
              if is_successful:
                print("\n" + "=" * 70)
                print("                ‚úÖ SUCC√àS - Code refactor√© et valid√©!")
                print(f"                   {reason}")
                print("=" * 70)
                
                return {
                    "success": True,
                    "reason": reason,
                    "iterations_used": iteration,
                    "files_processed": len(files),
                    "bugs_fixed": total_bugs_fixed,
                    "tests_passed": tests_passed,
                    "total_tests": tests_total,
                    "success_rate": success_rate,
                    "threshold": self.success_threshold,
                    "output_directory": str(self.target_directory)
                }
              else :
                print("\n" + "=" * 70)
                print(f"                ‚ö†Ô∏è  LIMITE ATTEINTE : {self.max_iterations} it√©rations max")
                print(f"                   {reason}")
                print("=" * 70)
                
                return {
                    "success": False,
                    "error": reason,
                    "iterations_used": iteration,
                    "files_processed": len(files),
                    "bugs_fixed": total_bugs_fixed,
                    "tests_passed": tests_passed,
                    "total_tests": tests_total,
                    "success_rate": success_rate,
                    "threshold": self.success_threshold,
                    "output_directory": str(self.target_directory)
                }
        
        # Cas par d√©faut (ne devrait jamais arriver)
        return {
            "success": False,
            "error": "Erreur inconnue",
            "iterations_used": self.max_iterations,
            "files_processed": len(files),
            "bugs_fixed": total_bugs_fixed,
            "tests_passed": 0,
            "total_tests": 0,
            "success_rate": 0.0,
            "threshold": self.success_threshold
        }